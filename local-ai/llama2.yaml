# https://github.com/go-skynet/model-gallery/blob/main/llama2-13b-chat-gguf.yaml
name: "llama2"

description: |
  Llama 2 chat in gguf format.
  Llama 2 is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters..

license: "https://ai.meta.com/llama/license/"
urls:
  - https://ai.meta.com/llama/
  - https://huggingface.co/TheBloke

config_file: |
  name: llama2
  backend: llama-cpp
  parameters:
    top_k: 80
    temperature: 0.2
    top_p: 0.7
  context_size: 4096
  roles:
    function: 'Function Result:'
    assistant_function_call: 'Function Call:'
    assistant: 'Assitant:'
    user: 'User:'
    system: 'System:'
  template:
    chat_message: llama2
  system_prompt: "You are a helpful assistant, below is a conversation, please respond with the next message and do not ask follow-up questions"

prompt_templates:
  - name: "llama2"
    content: |
      [INST]
      {{if .SystemPrompt}}<<SYS>>{{.SystemPrompt}}<</SYS>>{{end}}
      {{if .Input}}{{.Input}}{{end}}
      [/INST]

      Assistant:
